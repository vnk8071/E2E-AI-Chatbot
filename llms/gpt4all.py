from gpt4all import GPT4All

from llms.base import LLMBase


class GPT4AllModel(LLMBase):
    """Wrapper for the GPT4All model."""

    def __init__(
        self,
        model_path: str,
    ):
        try:
            model_path, delimiter, model_name = model_path.rpartition("/")
            model_path += delimiter
            self.model = GPT4All(model_name=model_name, model_path=model_path)
        except ImportError:
            raise ValueError(
                "Could not import gpt4all python package. "
                "Please install it with `poetry add gpt4all`."
            )

    def generate_prompt(self, system_content: str, question: str, context: str) -> str:
        if context is not None:
            context_ = "\n".join(doc.content for doc in context)
            system_prompt = f"""{system_content}.

            Use below context to answer the question.
            Context:
            {context_}

            Question:
            {question}
            """
        else:
            system_prompt = f"""{system_content}.

            Question:
            {question}
            """
        return system_prompt

    def __call__(self, system_content: str, question: str, context: str = "") -> str:
        """Call out to GPT4All's generate method.

        Args:
            question: The question to pass into the model.
            context: The related context to pass into the model.

        Returns:
            The string generated by the model.
        """
        text = ""
        for token in self.model.generate(
            self.generate_prompt(
                system_content=system_content, question=question, context=context
            )
        ):
            text += token
        return text


if __name__ == "__main__":
    model = GPT4AllModel(model_path="./models/ggml-gpt4all-j-v1.3-groovy.bin")
    question = "Hi, who are you?"
    answer = model(question)
